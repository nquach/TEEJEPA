# Example configuration file for VideoMAE finetuning
# This configuration file is used for finetuning VideoMAE models on classification or regression tasks

data:
  # Optimized dataset directories (created with litdata.optimize())
  train_optimized_dir: "path/to/train/optimized/dataset"
  val_optimized_dir: "path/to/val/optimized/dataset"  # Optional
  test_optimized_dir: "path/to/test/optimized/dataset"  # Optional
  
  # Cache directory for litdata
  cache_dir: "cache/finetune"
  max_cache_size: '50GB'
  
  # Subset ratio for training (0 < ratio <= 1, or null for full dataset)
  subset_ratio: null
  
  # Normalization (ImageNet defaults for classification)
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std: [0.229, 0.224, 0.225]
  
  # Cloud storage type (if using S3/remote datasets)
  cloud_type: 's3_public'  # or null for local datasets

model:
  # Backbone architecture: "vit-s" (small), "vit-b" (base), "vit-l" (large), or "vit-h" (huge)
  backbone: "vit-b"
  
  # Path to pretrained checkpoint from pretraining
  pretrained_path: "path/to/pretrained/checkpoint.pth"
  
  # Model key to look for in checkpoint (separated by '|' to try multiple keys)
  model_key: "model|module"
  
  # Prefix to add when loading state dict
  model_prefix: ""
  
  # Task type: "classification" or "regression" (default: "classification")
  # - "classification": Use CrossEntropyLoss, output num_classes logits, track accuracy metrics
  # - "regression": Use MSELoss or L1Loss, output output_dim values, track MSE/MAE/RÂ² metrics
  task_type: "classification"  # Change to "regression" for continuous variable prediction
  
  # Number of classes for classification (used when task_type="classification")
  num_classes: 101
  
  # Output dimension for regression (used when task_type="regression", default: 1 for single-value regression)
  output_dim: 1
  
  # Regression loss type: "mse" or "l1" (used when task_type="regression", default: "mse")
  regression_loss: "mse"
  
  # Input image size
  input_size: 224
  
  # Tubelet size for patch embedding
  tubelet_size: 2
  
  # Dropout rates
  fc_drop_rate: 0.0
  drop_rate: 0.0
  drop_path: 0.1
  attn_drop_rate: 0.0
  
  # Use mean pooling (recommended for finetuning)
  use_mean_pooling: true
  
  # Initial scale for head weights
  init_scale: 0.001
  
  # EVEREST Motion-Centric Masking (MCM) for finetuning
  mcm: true  # Enable motion-centric masking
  mcm_ratio: 0.4  # Ratio for MCM (default 0.4 for finetuning, vs 0.7 for pretraining)

training:
  # Number of frames
  num_frames: 16
  
  # Frame sampling
  frames_to_sample: 16
  temporal_stride: 1
  
  # Batch size
  batch_size: 8
  val_batch_size: 8  # Optional, defaults to batch_size
  test_batch_size: 8  # Optional, defaults to batch_size
  
  # Number of epochs
  max_epochs: 100
  
  # Data loading
  num_workers: 10
  pin_memory: true
  
  # Gradient clipping (0 to disable)
  gradient_clip_val: 0
  
  # Gradient accumulation
  accumulate_grad_batches: 1
  
  # Validation check interval (1.0 = every epoch, 0.5 = twice per epoch)
  val_check_interval: 1.0
  
  # Training strategy (ddp, deepspeed, etc.)
  strategy: "ddp"  # or "deepspeed" for DeepSpeed
  
  # Random seed
  seed: 0

optimizer:
  # Schedule-free optimizer type: "adamw" or "radam"
  type: "adamw"
  
  # Learning rate
  lr: 1e-3
  
  # Weight decay
  weight_decay: 0.05
  
  # Beta parameters for Adam-based optimizers
  betas: [0.9, 0.95]
  
  # Epsilon for numerical stability
  eps: 1e-8
  
  # Warmup steps (only applies to AdamWScheduleFree)
  warmup_steps: 0

augmentation:
  # Label smoothing
  label_smoothing: 0.1
  
  # Mixup alpha (0 to disable)
  mixup: 0.8
  
  # Cutmix alpha (0 to disable)
  cutmix: 1.0
  
  # Cutmix min/max ratios (null to use alpha instead)
  cutmix_minmax: null
  
  # Probability of applying mixup/cutmix
  mixup_prob: 1.0
  
  # Probability of switching to cutmix when both are active
  mixup_switch_prob: 0.5
  
  # Mixup mode: "batch", "pair", or "elem"
  mixup_mode: "batch"
  
  # Crop scale for RandomResizedCrop
  crop_scale: [0.75, 1.0]
  
  # Crop aspect ratio for RandomResizedCrop
  crop_aspect_ratio: [0.8, 1.2]

features:
  # Use gradient checkpointing (saves memory, slower)
  use_checkpoint: false
  
  # Track gradient norm
  track_grad_norm: false
  
  # Model EMA (Exponential Moving Average)
  model_ema: false
  model_ema_decay: 0.9999
  model_ema_force_cpu: false

checkpoint:
  # Enable checkpoint saving
  enable: true
  
  # Checkpoint directory
  dir: "checkpoints/finetune"
  
  # Checkpoint filename prefix
  prefix: "videomae_finetune"
  
  # Metric to monitor for best checkpoint
  # For classification: "val_acc1" (maximize, mode='max')
  # For regression: "val_mse" (minimize, mode='min')
  # The finetune.py script will automatically set mode based on task_type
  monitor: "val_acc1"  # For classification; use "val_mse" for regression
  
  # Save top K checkpoints
  save_top_k: 1
  
  # Whether to save the last checkpoint in addition to top_k (default: false to save disk space)
  save_last: false
  
  # Strict top K mode: if true, ensures ONLY top_k checkpoints exist (disables save_last)
  # When false, save_last and periodic saves (save_ckpt_freq) can create additional checkpoints
  strict_top_k: false
  
  # Save checkpoint every N epochs (null to save only best)
  # Periodic saves are still subject to top_k limit when strict_top_k=false
  save_ckpt_freq: null

logging:
  # Enable logging
  enable: true
  
  # Log directory
  log_dir: "logs"
  
  # Experiment name
  experiment_name: "finetune"
  
  # Log frequency (every N steps)
  log_freq: 10


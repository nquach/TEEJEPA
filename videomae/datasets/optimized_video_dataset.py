"""
Optimized Video Dataset using LitData StreamingDataset

This module provides a subclass of litdata's StreamingDataset for loading
optimized video datasets created with litdata.optimize(), with custom processing
for frame sampling, temporal downsampling, and transforms.
"""

import os
import random
import time
import warnings
import torch
from litdata import StreamingDataset, StreamingDataLoader
import numpy as np
from litdata.streaming.cache import Dir

# Suppress torchvision warnings (in case torchvision is used indirectly)
warnings.filterwarnings('ignore', category=UserWarning, module='torchvision')
warnings.filterwarnings('ignore', category=FutureWarning, module='torchvision')

class OptimizedVideoDataset(StreamingDataset):
    """
    Optimized video dataset using LitData StreamingDataset.
    
    This dataset inherits from StreamingDataset and loads videos from an optimized
    dataset created with litdata.optimize(). It applies the same frame sampling and
    temporal downsampling as CustomVideoDataset but uses the optimized data format
    for faster loading.
    
    Args:
        data_dir (str): Path to the optimized dataset directory
        frames_to_sample (int): Number of consecutive frames to sample (default: 32)
        temporal_stride (int): Stride for temporal downsampling (default: 2)
        subset_ratio (float, optional): Ratio of dataset to use (0 < ratio <= 1).
                                       If None, uses full dataset.
        seed (int, optional): Random seed for subset sampling reproducibility
        transform (callable, optional): Optional transform to apply to video frames
    """
    
    def __init__(
        self,
        data_dir,
        frames_to_sample=16,
        temporal_stride=1,
        subset_ratio=None,
        seed=None,
        transform=None,
        cache_dir=None,
        max_cache_size='50GB',
        drop_last=False,
        storage_options=None
    ):
        # Initialize parent StreamingDataset class
        # StreamingDataset is initialized with data_dir
        try:
            if subset_ratio is not None:
                super().__init__(input_dir=Dir(path=cache_dir, url=data_dir), 
                transform=None, subsample=subset_ratio, drop_last=drop_last, 
                max_cache_size=max_cache_size, storage_options=storage_options)
            else:
                super().__init__(input_dir=Dir(path=cache_dir, url=data_dir), 
                transform=None, drop_last=drop_last, max_cache_size=max_cache_size, 
                storage_options=storage_options)
        except Exception as e:
            raise RuntimeError(
                f"Failed to initialize StreamingDataset from {data_dir}. "
                f"Error: {e}"
            )
        
        # Store custom processing parameters
        self.frames_to_sample = frames_to_sample
        self.temporal_stride = temporal_stride
        self.custom_transform = transform 
        print(f"Loaded optimized dataset from {data_dir}")
    
    def __getitem__(self, idx):
        """
        Load and process a video sample from the optimized dataset.
        
        Args:
            idx (int or ChunkedIndex): Index of the video to load (ChunkedIndex when using StreamingDataLoader)
        
        Returns:
            tuple: (video_tensor, mask) where:
                - video_tensor: Tensor of shape [T, H, W, C] = [32, 224, 224, 3]
                - mask: Mask tensor for masking (will be generated by transform)
        """
        # Extract actual index from ChunkedIndex if needed
        # StreamingDataLoader passes ChunkedIndex objects, regular DataLoader passes integers

        data = super().__getitem__(idx)
        
        video = data['video'] #TCHW format

        num_frames = video.shape[0] #
        
        # Randomly sample consecutive frames
        max_start = num_frames - self.frames_to_sample
        if max_start <= 0:
            start_frame = 0
        else:
            start_frame = random.randint(0, max_start)
        
        # Extract consecutive frames
        sampled_frames = video[start_frame:start_frame + self.frames_to_sample]
        
        # Temporal downsampling with stride
        video_tensor = sampled_frames[::self.temporal_stride].float()
        max_val = video_tensor.max().item() if video_tensor.numel() > 0 else 0.0
        if max_val > 1.0:
            video_tensor = video_tensor / 255.0
        
        # Apply transform if provided (for masking, normalization, etc.)
        if self.custom_transform is not None:
            video_tensor, mask = self.custom_transform(video_tensor.permute(0,3,1,2)) #THWC -> TCHW
            return video_tensor, mask

        # Return video and None mask (mask will be generated elsewhere)
        return video_tensor.permute(3,0,1,2), None #TCHW -> CTHW
    

